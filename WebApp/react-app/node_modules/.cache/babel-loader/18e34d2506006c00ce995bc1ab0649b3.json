{"ast":null,"code":"var AWS = require('../core');\n\nvar v4Credentials = require('../signers/v4_credentials'); // Pull in managed upload extension\n\n\nrequire('../s3/managed_upload');\n/**\n * @api private\n */\n\n\nvar operationsWith200StatusCodeError = {\n  'completeMultipartUpload': true,\n  'copyObject': true,\n  'uploadPartCopy': true\n};\n/**\n * @api private\n */\n\nvar regionRedirectErrorCodes = ['AuthorizationHeaderMalformed', // non-head operations on virtual-hosted global bucket endpoints\n'BadRequest', // head operations on virtual-hosted global bucket endpoints\n'PermanentRedirect', // non-head operations on path-style or regional endpoints\n301 // head operations on path-style or regional endpoints\n];\nAWS.util.update(AWS.S3.prototype, {\n  /**\n   * @api private\n   */\n  getSignatureVersion: function getSignatureVersion(request) {\n    var defaultApiVersion = this.api.signatureVersion;\n    var userDefinedVersion = this._originalConfig ? this._originalConfig.signatureVersion : null;\n    var regionDefinedVersion = this.config.signatureVersion;\n    var isPresigned = request ? request.isPresigned() : false;\n    /*\n      1) User defined version specified:\n        a) always return user defined version\n      2) No user defined version specified:\n        a) default to lowest version the region supports\n        b) If using presigned urls, default to lowest version the region supports\n    */\n\n    if (userDefinedVersion) {\n      userDefinedVersion = userDefinedVersion === 'v2' ? 's3' : userDefinedVersion;\n      return userDefinedVersion;\n    }\n\n    if (isPresigned !== true) {\n      defaultApiVersion = 'v4';\n    } else if (regionDefinedVersion) {\n      defaultApiVersion = regionDefinedVersion;\n    }\n\n    return defaultApiVersion;\n  },\n\n  /**\n   * @api private\n   */\n  getSignerClass: function getSignerClass(request) {\n    var signatureVersion = this.getSignatureVersion(request);\n    return AWS.Signers.RequestSigner.getVersion(signatureVersion);\n  },\n\n  /**\n   * @api private\n   */\n  validateService: function validateService() {\n    var msg;\n    var messages = []; // default to us-east-1 when no region is provided\n\n    if (!this.config.region) this.config.region = 'us-east-1';\n\n    if (!this.config.endpoint && this.config.s3BucketEndpoint) {\n      messages.push('An endpoint must be provided when configuring ' + '`s3BucketEndpoint` to true.');\n    }\n\n    if (messages.length === 1) {\n      msg = messages[0];\n    } else if (messages.length > 1) {\n      msg = 'Multiple configuration errors:\\n' + messages.join('\\n');\n    }\n\n    if (msg) {\n      throw AWS.util.error(new Error(), {\n        name: 'InvalidEndpoint',\n        message: msg\n      });\n    }\n  },\n\n  /**\n   * @api private\n   */\n  shouldDisableBodySigning: function shouldDisableBodySigning(request) {\n    var signerClass = this.getSignerClass();\n\n    if (this.config.s3DisableBodySigning === true && signerClass === AWS.Signers.V4 && request.httpRequest.endpoint.protocol === 'https:') {\n      return true;\n    }\n\n    return false;\n  },\n\n  /**\n   * @api private\n   */\n  setupRequestListeners: function setupRequestListeners(request) {\n    var prependListener = true;\n    request.addListener('validate', this.validateScheme);\n    request.addListener('validate', this.validateBucketEndpoint);\n    request.addListener('validate', this.correctBucketRegionFromCache);\n    request.addListener('validate', this.validateBucketName, prependListener);\n    request.addListener('build', this.addContentType);\n    request.addListener('build', this.populateURI);\n    request.addListener('build', this.computeContentMd5);\n    request.addListener('build', this.computeSseCustomerKeyMd5);\n    request.addListener('afterBuild', this.addExpect100Continue);\n    request.removeListener('validate', AWS.EventListeners.Core.VALIDATE_REGION);\n    request.addListener('extractError', this.extractError);\n    request.onAsync('extractError', this.requestBucketRegion);\n    request.addListener('extractData', this.extractData);\n    request.addListener('extractData', AWS.util.hoistPayloadMember);\n    request.addListener('beforePresign', this.prepareSignedUrl);\n\n    if (AWS.util.isBrowser()) {\n      request.onAsync('retry', this.reqRegionForNetworkingError);\n    }\n\n    if (this.shouldDisableBodySigning(request)) {\n      request.removeListener('afterBuild', AWS.EventListeners.Core.COMPUTE_SHA256);\n      request.addListener('afterBuild', this.disableBodySigning);\n    }\n  },\n\n  /**\n   * @api private\n   */\n  validateScheme: function validateScheme(req) {\n    var params = req.params,\n        scheme = req.httpRequest.endpoint.protocol,\n        sensitive = params.SSECustomerKey || params.CopySourceSSECustomerKey;\n\n    if (sensitive && scheme !== 'https:') {\n      var msg = 'Cannot send SSE keys over HTTP. Set \\'sslEnabled\\'' + 'to \\'true\\' in your configuration';\n      throw AWS.util.error(new Error(), {\n        code: 'ConfigError',\n        message: msg\n      });\n    }\n  },\n\n  /**\n   * @api private\n   */\n  validateBucketEndpoint: function validateBucketEndpoint(req) {\n    if (!req.params.Bucket && req.service.config.s3BucketEndpoint) {\n      var msg = 'Cannot send requests to root API with `s3BucketEndpoint` set.';\n      throw AWS.util.error(new Error(), {\n        code: 'ConfigError',\n        message: msg\n      });\n    }\n  },\n\n  /**\n   * @api private\n   */\n  validateBucketName: function validateBucketName(req) {\n    var service = req.service;\n    var signatureVersion = service.getSignatureVersion(req);\n    var bucket = req.params && req.params.Bucket;\n    var key = req.params && req.params.Key;\n    var slashIndex = bucket && bucket.indexOf('/');\n\n    if (bucket && slashIndex >= 0) {\n      if (typeof key === 'string') {\n        req.params = AWS.util.copy(req.params); // Need to include trailing slash to match sigv2 behavior\n\n        var prefix = bucket.substr(slashIndex + 1) || '';\n        req.params.Key = prefix + '/' + key;\n        req.params.Bucket = bucket.substr(0, slashIndex);\n      } else if (signatureVersion === 'v4') {\n        var msg = 'Bucket names cannot contain forward slashes. Bucket: ' + bucket;\n        throw AWS.util.error(new Error(), {\n          code: 'InvalidBucket',\n          message: msg\n        });\n      }\n    }\n  },\n\n  /**\n   * @api private\n   */\n  isValidAccelerateOperation: function isValidAccelerateOperation(operation) {\n    var invalidOperations = ['createBucket', 'deleteBucket', 'listBuckets'];\n    return invalidOperations.indexOf(operation) === -1;\n  },\n\n  /**\n   * S3 prefers dns-compatible bucket names to be moved from the uri path\n   * to the hostname as a sub-domain.  This is not possible, even for dns-compat\n   * buckets when using SSL and the bucket name contains a dot ('.').  The\n   * ssl wildcard certificate is only 1-level deep.\n   *\n   * @api private\n   */\n  populateURI: function populateURI(req) {\n    var httpRequest = req.httpRequest;\n    var b = req.params.Bucket;\n    var service = req.service;\n    var endpoint = httpRequest.endpoint;\n\n    if (b) {\n      if (!service.pathStyleBucketName(b)) {\n        if (service.config.useAccelerateEndpoint && service.isValidAccelerateOperation(req.operation)) {\n          if (service.config.useDualstack) {\n            endpoint.hostname = b + '.s3-accelerate.dualstack.amazonaws.com';\n          } else {\n            endpoint.hostname = b + '.s3-accelerate.amazonaws.com';\n          }\n        } else if (!service.config.s3BucketEndpoint) {\n          endpoint.hostname = b + '.' + endpoint.hostname;\n        }\n\n        var port = endpoint.port;\n\n        if (port !== 80 && port !== 443) {\n          endpoint.host = endpoint.hostname + ':' + endpoint.port;\n        } else {\n          endpoint.host = endpoint.hostname;\n        }\n\n        httpRequest.virtualHostedBucket = b; // needed for signing the request\n\n        service.removeVirtualHostedBucketFromPath(req);\n      }\n    }\n  },\n\n  /**\n   * Takes the bucket name out of the path if bucket is virtual-hosted\n   *\n   * @api private\n   */\n  removeVirtualHostedBucketFromPath: function removeVirtualHostedBucketFromPath(req) {\n    var httpRequest = req.httpRequest;\n    var bucket = httpRequest.virtualHostedBucket;\n\n    if (bucket && httpRequest.path) {\n      if (req.params && req.params.Key) {\n        if (httpRequest.path.indexOf('/' + AWS.util.uriEscapePath(req.params.Key)) === 0) {\n          return;\n        }\n      }\n\n      httpRequest.path = httpRequest.path.replace(new RegExp('/' + bucket), '');\n\n      if (httpRequest.path[0] !== '/') {\n        httpRequest.path = '/' + httpRequest.path;\n      }\n    }\n  },\n\n  /**\n   * Adds Expect: 100-continue header if payload is greater-or-equal 1MB\n   * @api private\n   */\n  addExpect100Continue: function addExpect100Continue(req) {\n    var len = req.httpRequest.headers['Content-Length'];\n\n    if (AWS.util.isNode() && len >= 1024 * 1024) {\n      req.httpRequest.headers['Expect'] = '100-continue';\n    }\n  },\n\n  /**\n   * Adds a default content type if none is supplied.\n   *\n   * @api private\n   */\n  addContentType: function addContentType(req) {\n    var httpRequest = req.httpRequest;\n\n    if (httpRequest.method === 'GET' || httpRequest.method === 'HEAD') {\n      // Content-Type is not set in GET/HEAD requests\n      delete httpRequest.headers['Content-Type'];\n      return;\n    }\n\n    if (!httpRequest.headers['Content-Type']) {\n      // always have a Content-Type\n      httpRequest.headers['Content-Type'] = 'application/octet-stream';\n    }\n\n    var contentType = httpRequest.headers['Content-Type'];\n\n    if (AWS.util.isBrowser()) {\n      if (typeof httpRequest.body === 'string' && !contentType.match(/;\\s*charset=/)) {\n        var charset = '; charset=UTF-8';\n        httpRequest.headers['Content-Type'] += charset;\n      } else {\n        var replaceFn = function replaceFn(_, prefix, charsetName) {\n          return prefix + charsetName.toUpperCase();\n        };\n\n        httpRequest.headers['Content-Type'] = contentType.replace(/(;\\s*charset=)(.+)$/, replaceFn);\n      }\n    }\n  },\n\n  /**\n   * @api private\n   */\n  computableChecksumOperations: {\n    putBucketCors: true,\n    putBucketLifecycle: true,\n    putBucketLifecycleConfiguration: true,\n    putBucketTagging: true,\n    deleteObjects: true,\n    putBucketReplication: true\n  },\n\n  /**\n   * Checks whether checksums should be computed for the request.\n   * If the request requires checksums to be computed, this will always\n   * return true, otherwise it depends on whether {AWS.Config.computeChecksums}\n   * is set.\n   *\n   * @param req [AWS.Request] the request to check against\n   * @return [Boolean] whether to compute checksums for a request.\n   * @api private\n   */\n  willComputeChecksums: function willComputeChecksums(req) {\n    if (this.computableChecksumOperations[req.operation]) return true;\n    if (!this.config.computeChecksums) return false; // TODO: compute checksums for Stream objects\n\n    if (!AWS.util.Buffer.isBuffer(req.httpRequest.body) && typeof req.httpRequest.body !== 'string') {\n      return false;\n    }\n\n    var rules = req.service.api.operations[req.operation].input.members; // Sha256 signing disabled, and not a presigned url\n\n    if (req.service.shouldDisableBodySigning(req) && !Object.prototype.hasOwnProperty.call(req.httpRequest.headers, 'presigned-expires')) {\n      if (rules.ContentMD5 && !req.params.ContentMD5) {\n        return true;\n      }\n    } // V4 signer uses SHA256 signatures so only compute MD5 if it is required\n\n\n    if (req.service.getSignerClass(req) === AWS.Signers.V4) {\n      if (rules.ContentMD5 && !rules.ContentMD5.required) return false;\n    }\n\n    if (rules.ContentMD5 && !req.params.ContentMD5) return true;\n  },\n\n  /**\n   * A listener that computes the Content-MD5 and sets it in the header.\n   * @see AWS.S3.willComputeChecksums\n   * @api private\n   */\n  computeContentMd5: function computeContentMd5(req) {\n    if (req.service.willComputeChecksums(req)) {\n      var md5 = AWS.util.crypto.md5(req.httpRequest.body, 'base64');\n      req.httpRequest.headers['Content-MD5'] = md5;\n    }\n  },\n\n  /**\n   * @api private\n   */\n  computeSseCustomerKeyMd5: function computeSseCustomerKeyMd5(req) {\n    var keys = {\n      SSECustomerKey: 'x-amz-server-side-encryption-customer-key-MD5',\n      CopySourceSSECustomerKey: 'x-amz-copy-source-server-side-encryption-customer-key-MD5'\n    };\n    AWS.util.each(keys, function (key, header) {\n      if (req.params[key]) {\n        var value = AWS.util.crypto.md5(req.params[key], 'base64');\n        req.httpRequest.headers[header] = value;\n      }\n    });\n  },\n\n  /**\n   * Returns true if the bucket name should be left in the URI path for\n   * a request to S3.  This function takes into account the current\n   * endpoint protocol (e.g. http or https).\n   *\n   * @api private\n   */\n  pathStyleBucketName: function pathStyleBucketName(bucketName) {\n    // user can force path style requests via the configuration\n    if (this.config.s3ForcePathStyle) return true;\n    if (this.config.s3BucketEndpoint) return false;\n\n    if (this.dnsCompatibleBucketName(bucketName)) {\n      return this.config.sslEnabled && bucketName.match(/\\./) ? true : false;\n    } else {\n      return true; // not dns compatible names must always use path style\n    }\n  },\n\n  /**\n   * Returns true if the bucket name is DNS compatible.  Buckets created\n   * outside of the classic region MUST be DNS compatible.\n   *\n   * @api private\n   */\n  dnsCompatibleBucketName: function dnsCompatibleBucketName(bucketName) {\n    var b = bucketName;\n    var domain = new RegExp(/^[a-z0-9][a-z0-9\\.\\-]{1,61}[a-z0-9]$/);\n    var ipAddress = new RegExp(/(\\d+\\.){3}\\d+/);\n    var dots = new RegExp(/\\.\\./);\n    return b.match(domain) && !b.match(ipAddress) && !b.match(dots) ? true : false;\n  },\n\n  /**\n   * @return [Boolean] whether response contains an error\n   * @api private\n   */\n  successfulResponse: function successfulResponse(resp) {\n    var req = resp.request;\n    var httpResponse = resp.httpResponse;\n\n    if (operationsWith200StatusCodeError[req.operation] && httpResponse.body.toString().match('<Error>')) {\n      return false;\n    } else {\n      return httpResponse.statusCode < 300;\n    }\n  },\n\n  /**\n   * @return [Boolean] whether the error can be retried\n   * @api private\n   */\n  retryableError: function retryableError(error, request) {\n    if (operationsWith200StatusCodeError[request.operation] && error.statusCode === 200) {\n      return true;\n    } else if (request._requestRegionForBucket && request.service.bucketRegionCache[request._requestRegionForBucket]) {\n      return false;\n    } else if (error && error.code === 'RequestTimeout') {\n      return true;\n    } else if (error && regionRedirectErrorCodes.indexOf(error.code) != -1 && error.region && error.region != request.httpRequest.region) {\n      request.httpRequest.region = error.region;\n\n      if (error.statusCode === 301) {\n        request.service.updateReqBucketRegion(request);\n      }\n\n      return true;\n    } else {\n      var _super = AWS.Service.prototype.retryableError;\n      return _super.call(this, error, request);\n    }\n  },\n\n  /**\n   * Updates httpRequest with region. If region is not provided, then\n   * the httpRequest will be updated based on httpRequest.region\n   *\n   * @api private\n   */\n  updateReqBucketRegion: function updateReqBucketRegion(request, region) {\n    var httpRequest = request.httpRequest;\n\n    if (typeof region === 'string' && region.length) {\n      httpRequest.region = region;\n    }\n\n    if (!httpRequest.endpoint.host.match(/s3(?!-accelerate).*\\.amazonaws\\.com$/)) {\n      return;\n    }\n\n    var service = request.service;\n    var s3Config = service.config;\n    var s3BucketEndpoint = s3Config.s3BucketEndpoint;\n\n    if (s3BucketEndpoint) {\n      delete s3Config.s3BucketEndpoint;\n    }\n\n    var newConfig = AWS.util.copy(s3Config);\n    delete newConfig.endpoint;\n    newConfig.region = httpRequest.region;\n    httpRequest.endpoint = new AWS.S3(newConfig).endpoint;\n    service.populateURI(request);\n    s3Config.s3BucketEndpoint = s3BucketEndpoint;\n    httpRequest.headers.Host = httpRequest.endpoint.host;\n\n    if (request._asm.currentState === 'validate') {\n      request.removeListener('build', service.populateURI);\n      request.addListener('build', service.removeVirtualHostedBucketFromPath);\n    }\n  },\n\n  /**\n   * Provides a specialized parser for getBucketLocation -- all other\n   * operations are parsed by the super class.\n   *\n   * @api private\n   */\n  extractData: function extractData(resp) {\n    var req = resp.request;\n\n    if (req.operation === 'getBucketLocation') {\n      var match = resp.httpResponse.body.toString().match(/>(.+)<\\/Location/);\n      delete resp.data['_'];\n\n      if (match) {\n        resp.data.LocationConstraint = match[1];\n      } else {\n        resp.data.LocationConstraint = '';\n      }\n    }\n\n    var bucket = req.params.Bucket || null;\n\n    if (req.operation === 'deleteBucket' && typeof bucket === 'string' && !resp.error) {\n      req.service.clearBucketRegionCache(bucket);\n    } else {\n      var headers = resp.httpResponse.headers || {};\n      var region = headers['x-amz-bucket-region'] || null;\n\n      if (!region && req.operation === 'createBucket' && !resp.error) {\n        var createBucketConfiguration = req.params.CreateBucketConfiguration;\n\n        if (!createBucketConfiguration) {\n          region = 'us-east-1';\n        } else if (createBucketConfiguration.LocationConstraint === 'EU') {\n          region = 'eu-west-1';\n        } else {\n          region = createBucketConfiguration.LocationConstraint;\n        }\n      }\n\n      if (region) {\n        if (bucket && region !== req.service.bucketRegionCache[bucket]) {\n          req.service.bucketRegionCache[bucket] = region;\n        }\n      }\n    }\n\n    req.service.extractRequestIds(resp);\n  },\n\n  /**\n   * Extracts an error object from the http response.\n   *\n   * @api private\n   */\n  extractError: function extractError(resp) {\n    var codes = {\n      304: 'NotModified',\n      403: 'Forbidden',\n      400: 'BadRequest',\n      404: 'NotFound'\n    };\n    var req = resp.request;\n    var code = resp.httpResponse.statusCode;\n    var body = resp.httpResponse.body || '';\n    var headers = resp.httpResponse.headers || {};\n    var region = headers['x-amz-bucket-region'] || null;\n    var bucket = req.params.Bucket || null;\n    var bucketRegionCache = req.service.bucketRegionCache;\n\n    if (region && bucket && region !== bucketRegionCache[bucket]) {\n      bucketRegionCache[bucket] = region;\n    }\n\n    var cachedRegion;\n\n    if (codes[code] && body.length === 0) {\n      if (bucket && !region) {\n        cachedRegion = bucketRegionCache[bucket] || null;\n\n        if (cachedRegion !== req.httpRequest.region) {\n          region = cachedRegion;\n        }\n      }\n\n      resp.error = AWS.util.error(new Error(), {\n        code: codes[code],\n        message: null,\n        region: region\n      });\n    } else {\n      var data = new AWS.XML.Parser().parse(body.toString());\n\n      if (data.Region && !region) {\n        region = data.Region;\n\n        if (bucket && region !== bucketRegionCache[bucket]) {\n          bucketRegionCache[bucket] = region;\n        }\n      } else if (bucket && !region && !data.Region) {\n        cachedRegion = bucketRegionCache[bucket] || null;\n\n        if (cachedRegion !== req.httpRequest.region) {\n          region = cachedRegion;\n        }\n      }\n\n      resp.error = AWS.util.error(new Error(), {\n        code: data.Code || code,\n        message: data.Message || null,\n        region: region\n      });\n    }\n\n    req.service.extractRequestIds(resp);\n  },\n\n  /**\n   * If region was not obtained synchronously, then send async request\n   * to get bucket region for errors resulting from wrong region.\n   *\n   * @api private\n   */\n  requestBucketRegion: function requestBucketRegion(resp, done) {\n    var error = resp.error;\n    var req = resp.request;\n    var bucket = req.params.Bucket || null;\n\n    if (!error || !bucket || error.region || req.operation === 'listObjects' || AWS.util.isNode() && req.operation === 'headBucket' || error.statusCode === 400 && req.operation !== 'headObject' || regionRedirectErrorCodes.indexOf(error.code) === -1) {\n      return done();\n    }\n\n    var reqOperation = AWS.util.isNode() ? 'headBucket' : 'listObjects';\n    var reqParams = {\n      Bucket: bucket\n    };\n    if (reqOperation === 'listObjects') reqParams.MaxKeys = 0;\n    var regionReq = req.service[reqOperation](reqParams);\n    regionReq._requestRegionForBucket = bucket;\n    regionReq.send(function () {\n      var region = req.service.bucketRegionCache[bucket] || null;\n      error.region = region;\n      done();\n    });\n  },\n\n  /**\n  * For browser only. If NetworkingError received, will attempt to obtain\n  * the bucket region.\n  *\n  * @api private\n  */\n  reqRegionForNetworkingError: function reqRegionForNetworkingError(resp, done) {\n    if (!AWS.util.isBrowser()) {\n      return done();\n    }\n\n    var error = resp.error;\n    var request = resp.request;\n    var bucket = request.params.Bucket;\n\n    if (!error || error.code !== 'NetworkingError' || !bucket || request.httpRequest.region === 'us-east-1') {\n      return done();\n    }\n\n    var service = request.service;\n    var bucketRegionCache = service.bucketRegionCache;\n    var cachedRegion = bucketRegionCache[bucket] || null;\n\n    if (cachedRegion && cachedRegion !== request.httpRequest.region) {\n      service.updateReqBucketRegion(request, cachedRegion);\n      done();\n    } else if (!service.dnsCompatibleBucketName(bucket)) {\n      service.updateReqBucketRegion(request, 'us-east-1');\n\n      if (bucketRegionCache[bucket] !== 'us-east-1') {\n        bucketRegionCache[bucket] = 'us-east-1';\n      }\n\n      done();\n    } else if (request.httpRequest.virtualHostedBucket) {\n      var getRegionReq = service.listObjects({\n        Bucket: bucket,\n        MaxKeys: 0\n      });\n      service.updateReqBucketRegion(getRegionReq, 'us-east-1');\n      getRegionReq._requestRegionForBucket = bucket;\n      getRegionReq.send(function () {\n        var region = service.bucketRegionCache[bucket] || null;\n\n        if (region && region !== request.httpRequest.region) {\n          service.updateReqBucketRegion(request, region);\n        }\n\n        done();\n      });\n    } else {\n      // DNS-compatible path-style\n      // (s3ForcePathStyle or bucket name with dot over https)\n      // Cannot obtain region information for this case\n      done();\n    }\n  },\n\n  /**\n   * Cache for bucket region.\n   *\n   * @api private\n   */\n  bucketRegionCache: {},\n\n  /**\n   * Clears bucket region cache.\n   *\n   * @api private\n   */\n  clearBucketRegionCache: function clearBucketRegionCache(buckets) {\n    var bucketRegionCache = this.bucketRegionCache;\n\n    if (!buckets) {\n      buckets = Object.keys(bucketRegionCache);\n    } else if (typeof buckets === 'string') {\n      buckets = [buckets];\n    }\n\n    for (var i = 0; i < buckets.length; i++) {\n      delete bucketRegionCache[buckets[i]];\n    }\n\n    return bucketRegionCache;\n  },\n\n  /**\n   * Corrects request region if bucket's cached region is different\n   *\n   * @api private\n   */\n  correctBucketRegionFromCache: function correctBucketRegionFromCache(req) {\n    var bucket = req.params.Bucket || null;\n\n    if (bucket) {\n      var service = req.service;\n      var requestRegion = req.httpRequest.region;\n      var cachedRegion = service.bucketRegionCache[bucket];\n\n      if (cachedRegion && cachedRegion !== requestRegion) {\n        service.updateReqBucketRegion(req, cachedRegion);\n      }\n    }\n  },\n\n  /**\n   * Extracts S3 specific request ids from the http response.\n   *\n   * @api private\n   */\n  extractRequestIds: function extractRequestIds(resp) {\n    var extendedRequestId = resp.httpResponse.headers ? resp.httpResponse.headers['x-amz-id-2'] : null;\n    var cfId = resp.httpResponse.headers ? resp.httpResponse.headers['x-amz-cf-id'] : null;\n    resp.extendedRequestId = extendedRequestId;\n    resp.cfId = cfId;\n\n    if (resp.error) {\n      resp.error.requestId = resp.requestId || null;\n      resp.error.extendedRequestId = extendedRequestId;\n      resp.error.cfId = cfId;\n    }\n  },\n\n  /**\n   * Get a pre-signed URL for a given operation name.\n   *\n   * @note You must ensure that you have static or previously resolved\n   *   credentials if you call this method synchronously (with no callback),\n   *   otherwise it may not properly sign the request. If you cannot guarantee\n   *   this (you are using an asynchronous credential provider, i.e., EC2\n   *   IAM roles), you should always call this method with an asynchronous\n   *   callback.\n   * @note Not all operation parameters are supported when using pre-signed\n   *   URLs. Certain parameters, such as `SSECustomerKey`, `ACL`, `Expires`,\n   *   `ContentLength`, or `Tagging` must be provided as headers when sending a\n   *   request. If you are using pre-signed URLs to upload from a browser and\n   *   need to use these fields, see {createPresignedPost}.\n   * @param operation [String] the name of the operation to call\n   * @param params [map] parameters to pass to the operation. See the given\n   *   operation for the expected operation parameters. In addition, you can\n   *   also pass the \"Expires\" parameter to inform S3 how long the URL should\n   *   work for.\n   * @option params Expires [Integer] (900) the number of seconds to expire\n   *   the pre-signed URL operation in. Defaults to 15 minutes.\n   * @param callback [Function] if a callback is provided, this function will\n   *   pass the URL as the second parameter (after the error parameter) to\n   *   the callback function.\n   * @return [String] if called synchronously (with no callback), returns the\n   *   signed URL.\n   * @return [null] nothing is returned if a callback is provided.\n   * @example Pre-signing a getObject operation (synchronously)\n   *   var params = {Bucket: 'bucket', Key: 'key'};\n   *   var url = s3.getSignedUrl('getObject', params);\n   *   console.log('The URL is', url);\n   * @example Pre-signing a putObject (asynchronously)\n   *   var params = {Bucket: 'bucket', Key: 'key'};\n   *   s3.getSignedUrl('putObject', params, function (err, url) {\n   *     console.log('The URL is', url);\n   *   });\n   * @example Pre-signing a putObject operation with a specific payload\n   *   var params = {Bucket: 'bucket', Key: 'key', Body: 'body'};\n   *   var url = s3.getSignedUrl('putObject', params);\n   *   console.log('The URL is', url);\n   * @example Passing in a 1-minute expiry time for a pre-signed URL\n   *   var params = {Bucket: 'bucket', Key: 'key', Expires: 60};\n   *   var url = s3.getSignedUrl('getObject', params);\n   *   console.log('The URL is', url); // expires in 60 seconds\n   */\n  getSignedUrl: function getSignedUrl(operation, params, callback) {\n    params = AWS.util.copy(params || {});\n    var expires = params.Expires || 900;\n    delete params.Expires; // we can't validate this\n\n    var request = this.makeRequest(operation, params);\n\n    if (callback) {\n      AWS.util.defer(function () {\n        request.presign(expires, callback);\n      });\n    } else {\n      return request.presign(expires, callback);\n    }\n  },\n\n  /**\n   * Get a pre-signed POST policy to support uploading to S3 directly from an\n   * HTML form.\n   *\n   * @param params [map]\n   * @option params Bucket [String]     The bucket to which the post should be\n   *                                    uploaded\n   * @option params Expires [Integer]   (3600) The number of seconds for which\n   *                                    the presigned policy should be valid.\n   * @option params Conditions [Array]  An array of conditions that must be met\n   *                                    for the presigned policy to allow the\n   *                                    upload. This can include required tags,\n   *                                    the accepted range for content lengths,\n   *                                    etc.\n   * @see http://docs.aws.amazon.com/AmazonS3/latest/API/sigv4-HTTPPOSTConstructPolicy.html\n   * @option params Fields [map]        Fields to include in the form. All\n   *                                    values passed in as fields will be\n   *                                    signed as exact match conditions.\n   * @param callback [Function]\n   *\n   * @note All fields passed in when creating presigned post data will be signed\n   *   as exact match conditions. Any fields that will be interpolated by S3\n   *   must be added to the fields hash after signing, and an appropriate\n   *   condition for such fields must be explicitly added to the Conditions\n   *   array passed to this function before signing.\n   *\n   * @example Presiging post data with a known key\n   *   var params = {\n   *     Bucket: 'bucket',\n   *     Fields: {\n   *       key: 'key'\n   *     }\n   *   };\n   *   s3.createPresignedPost(params, function(err, data) {\n   *     if (err) {\n   *       console.error('Presigning post data encountered an error', err);\n   *     } else {\n   *       console.log('The post data is', data);\n   *     }\n   *   });\n   *\n   * @example Presigning post data with an interpolated key\n   *   var params = {\n   *     Bucket: 'bucket',\n   *     Conditions: [\n   *       ['starts-with', '$key', 'path/to/uploads/']\n   *     ]\n   *   };\n   *   s3.createPresignedPost(params, function(err, data) {\n   *     if (err) {\n   *       console.error('Presigning post data encountered an error', err);\n   *     } else {\n   *       data.Fields.key = 'path/to/uploads/${filename}';\n   *       console.log('The post data is', data);\n   *     }\n   *   });\n   *\n   * @note You must ensure that you have static or previously resolved\n   *   credentials if you call this method synchronously (with no callback),\n   *   otherwise it may not properly sign the request. If you cannot guarantee\n   *   this (you are using an asynchronous credential provider, i.e., EC2\n   *   IAM roles), you should always call this method with an asynchronous\n   *   callback.\n   *\n   * @return [map]  If called synchronously (with no callback), returns a hash\n   *                with the url to set as the form action and a hash of fields\n   *                to include in the form.\n   * @return [null] Nothing is returned if a callback is provided.\n   *\n   * @callback callback function (err, data)\n   *  @param err [Error] the error object returned from the policy signer\n   *  @param data [map] The data necessary to construct an HTML form\n   *  @param data.url [String] The URL to use as the action of the form\n   *  @param data.fields [map] A hash of fields that must be included in the\n   *                           form for the upload to succeed. This hash will\n   *                           include the signed POST policy, your access key\n   *                           ID and security token (if present), etc. These\n   *                           may be safely included as input elements of type\n   *                           'hidden.'\n   */\n  createPresignedPost: function createPresignedPost(params, callback) {\n    if (typeof params === 'function' && callback === undefined) {\n      callback = params;\n      params = null;\n    }\n\n    params = AWS.util.copy(params || {});\n    var boundParams = this.config.params || {};\n    var bucket = params.Bucket || boundParams.Bucket,\n        self = this,\n        config = this.config,\n        endpoint = AWS.util.copy(this.endpoint);\n\n    if (!config.s3BucketEndpoint) {\n      endpoint.pathname = '/' + bucket;\n    }\n\n    function finalizePost() {\n      return {\n        url: AWS.util.urlFormat(endpoint),\n        fields: self.preparePostFields(config.credentials, config.region, bucket, params.Fields, params.Conditions, params.Expires)\n      };\n    }\n\n    if (callback) {\n      config.getCredentials(function (err) {\n        if (err) {\n          callback(err);\n        }\n\n        callback(null, finalizePost());\n      });\n    } else {\n      return finalizePost();\n    }\n  },\n\n  /**\n   * @api private\n   */\n  preparePostFields: function preparePostFields(credentials, region, bucket, fields, conditions, expiresInSeconds) {\n    var now = this.getSkewCorrectedDate();\n\n    if (!credentials || !region || !bucket) {\n      throw new Error('Unable to create a POST object policy without a bucket,' + ' region, and credentials');\n    }\n\n    fields = AWS.util.copy(fields || {});\n    conditions = (conditions || []).slice(0);\n    expiresInSeconds = expiresInSeconds || 3600;\n    var signingDate = AWS.util.date.iso8601(now).replace(/[:\\-]|\\.\\d{3}/g, '');\n    var shortDate = signingDate.substr(0, 8);\n    var scope = v4Credentials.createScope(shortDate, region, 's3');\n    var credential = credentials.accessKeyId + '/' + scope;\n    fields['bucket'] = bucket;\n    fields['X-Amz-Algorithm'] = 'AWS4-HMAC-SHA256';\n    fields['X-Amz-Credential'] = credential;\n    fields['X-Amz-Date'] = signingDate;\n\n    if (credentials.sessionToken) {\n      fields['X-Amz-Security-Token'] = credentials.sessionToken;\n    }\n\n    for (var field in fields) {\n      if (fields.hasOwnProperty(field)) {\n        var condition = {};\n        condition[field] = fields[field];\n        conditions.push(condition);\n      }\n    }\n\n    fields.Policy = this.preparePostPolicy(new Date(now.valueOf() + expiresInSeconds * 1000), conditions);\n    fields['X-Amz-Signature'] = AWS.util.crypto.hmac(v4Credentials.getSigningKey(credentials, shortDate, region, 's3', true), fields.Policy, 'hex');\n    return fields;\n  },\n\n  /**\n   * @api private\n   */\n  preparePostPolicy: function preparePostPolicy(expiration, conditions) {\n    return AWS.util.base64.encode(JSON.stringify({\n      expiration: AWS.util.date.iso8601(expiration),\n      conditions: conditions\n    }));\n  },\n\n  /**\n   * @api private\n   */\n  prepareSignedUrl: function prepareSignedUrl(request) {\n    request.addListener('validate', request.service.noPresignedContentLength);\n    request.removeListener('build', request.service.addContentType);\n\n    if (!request.params.Body) {\n      // no Content-MD5/SHA-256 if body is not provided\n      request.removeListener('build', request.service.computeContentMd5);\n    } else {\n      request.addListener('afterBuild', AWS.EventListeners.Core.COMPUTE_SHA256);\n    }\n  },\n\n  /**\n   * @api private\n   * @param request\n   */\n  disableBodySigning: function disableBodySigning(request) {\n    var headers = request.httpRequest.headers; // Add the header to anything that isn't a presigned url, unless that presigned url had a body defined\n\n    if (!Object.prototype.hasOwnProperty.call(headers, 'presigned-expires')) {\n      headers['X-Amz-Content-Sha256'] = 'UNSIGNED-PAYLOAD';\n    }\n  },\n\n  /**\n   * @api private\n   */\n  noPresignedContentLength: function noPresignedContentLength(request) {\n    if (request.params.ContentLength !== undefined) {\n      throw AWS.util.error(new Error(), {\n        code: 'UnexpectedParameter',\n        message: 'ContentLength is not supported in pre-signed URLs.'\n      });\n    }\n  },\n  createBucket: function createBucket(params, callback) {\n    // When creating a bucket *outside* the classic region, the location\n    // constraint must be set for the bucket and it must match the endpoint.\n    // This chunk of code will set the location constraint param based\n    // on the region (when possible), but it will not override a passed-in\n    // location constraint.\n    if (typeof params === 'function' || !params) {\n      callback = callback || params;\n      params = {};\n    }\n\n    var hostname = this.endpoint.hostname;\n\n    if (hostname !== this.api.globalEndpoint && !params.CreateBucketConfiguration) {\n      params.CreateBucketConfiguration = {\n        LocationConstraint: this.config.region\n      };\n    }\n\n    return this.makeRequest('createBucket', params, callback);\n  },\n\n  /**\n   * @see AWS.S3.ManagedUpload\n   * @overload upload(params = {}, [options], [callback])\n   *   Uploads an arbitrarily sized buffer, blob, or stream, using intelligent\n   *   concurrent handling of parts if the payload is large enough. You can\n   *   configure the concurrent queue size by setting `options`. Note that this\n   *   is the only operation for which the SDK can retry requests with stream\n   *   bodies.\n   *\n   *   @param (see AWS.S3.putObject)\n   *   @option (see AWS.S3.ManagedUpload.constructor)\n   *   @return [AWS.S3.ManagedUpload] the managed upload object that can call\n   *     `send()` or track progress.\n   *   @example Uploading a stream object\n   *     var params = {Bucket: 'bucket', Key: 'key', Body: stream};\n   *     s3.upload(params, function(err, data) {\n   *       console.log(err, data);\n   *     });\n   *   @example Uploading a stream with concurrency of 1 and partSize of 10mb\n   *     var params = {Bucket: 'bucket', Key: 'key', Body: stream};\n   *     var options = {partSize: 10 * 1024 * 1024, queueSize: 1};\n   *     s3.upload(params, options, function(err, data) {\n   *       console.log(err, data);\n   *     });\n   * @callback callback function(err, data)\n   *   @param err [Error] an error or null if no error occurred.\n   *   @param data [map] The response data from the successful upload:\n   *   @param data.Location [String] the URL of the uploaded object\n   *   @param data.ETag [String] the ETag of the uploaded object\n   *   @param data.Bucket [String]  the bucket to which the object was uploaded\n   *   @param data.Key [String] the key to which the object was uploaded\n   */\n  upload: function upload(params, options, callback) {\n    if (typeof options === 'function' && callback === undefined) {\n      callback = options;\n      options = null;\n    }\n\n    options = options || {};\n    options = AWS.util.merge(options || {}, {\n      service: this,\n      params: params\n    });\n    var uploader = new AWS.S3.ManagedUpload(options);\n    if (typeof callback === 'function') uploader.send(callback);\n    return uploader;\n  }\n});","map":null,"metadata":{},"sourceType":"script"}